import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq
import os

from google.colab import drive
drive.mount('/content/drive')

# Directories
input_dir  = '/content/drive/My Drive/Colab Notebooks/mimic_input/'
output_dir = '/content/drive/My Drive/Colab Notebooks/mimic_output_pyarrow/'
os.makedirs(output_dir, exist_ok=True)

# File mapping
csv_files = {
    'admissions':    'ADMISSIONS.csv',
    'patients':      'PATIENTS.csv',
    'icustays':      'ICUSTAYS.csv',
    'labevents':     'LABEVENTS.csv',
    'diagnoses_icd': 'DIAGNOSES_ICD.csv',
}

def clean_transform(df, key):
    """Apply the same cleaning & imputation logic you used before."""
    df.columns = df.columns.str.lower()

    if key == 'admissions':
        for dt in ['admittime','dischtime','deathtime','edregtime','edouttime']:
            if dt in df:
                df[dt] = pd.to_datetime(df[dt], errors='coerce')
        df['length_of_stay'] = (df['dischtime'] - df['admittime']).dt.days.fillna(0).astype(int)
        for cat in ['admission_type','insurance','ethnicity','hospital_expire_flag']:
            if cat in df:
                df[cat] = df[cat].fillna('unknown')

    elif key == 'patients':
        df['dob'] = pd.to_datetime(df['dob'], errors='coerce')
        df['dod'] = pd.to_datetime(df['dod'], errors='coerce')
        for cat in ['gender','expire_flag']:
            if cat in df:
                df[cat] = df[cat].fillna('unknown')

    elif key == 'icustays':
        df['intime'] = pd.to_datetime(df['intime'], errors='coerce')
        df['outtime'] = pd.to_datetime(df['outtime'], errors='coerce')
        df['icu_length_of_stay'] = (df['outtime'] - df['intime']).dt.days.fillna(0).astype(int)
        for cat in ['first_careunit','last_careunit']:
            if cat in df:
                df[cat] = df[cat].fillna('unknown')

    elif key == 'labevents':
        df['charttime'] = pd.to_datetime(df['charttime'], errors='coerce')
        df['valuenum'] = pd.to_numeric(df['valuenum'], errors='coerce').fillna(0.0)
        if 'valueuom' in df:
            df['valueuom'] = df['valueuom'].fillna('unknown')

    elif key == 'diagnoses_icd':
        if 'icd9_code' in df:
            df = df.rename(columns={'icd9_code':'diagnosis_code'})
        df['seq_num'] = df['seq_num'].fillna(-1).astype(int)

    return df

for key, fname in csv_files.items():
    path = os.path.join(input_dir, fname)
    if not os.path.exists(path):
        print(f"Missing {fname}, skipping")
        continue

    # 1. Read & clean
    df = pd.read_csv(path)
    df = clean_transform(df, key)

    # 2. Convert to PyArrow Table
    table = pa.Table.from_pandas(df, preserve_index=False)

    # 3. Write Parquet with int96 timestamps
    out_path = os.path.join(output_dir, f"{key}.parquet")
    pq.write_table(
        table,
        out_path,
        use_deprecated_int96_timestamps=True
    )
    print(f"Wrote {out_path} ({df.shape[0]} rows)")



# List all Parquet files in the directory
parquet_files = [f for f in os.listdir(output_dir) if f.endswith('.parquet')]

# Function to display DataFrame as a table
def display_table(file_path):
    print(f"Displaying table from: {file_path}")
    df = pd.read_parquet(file_path)
    print(f"Shape: {df.shape}")
    display(df.head())  # Display the first few rows as a table

# Iterate through and display all Parquet files
for parquet_file in parquet_files:
    file_path = os.path.join(output_dir, parquet_file)
    display_table(file_path)
